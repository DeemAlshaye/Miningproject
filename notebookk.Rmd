---
title: "Data Salaries"
output:
  html_document:
    toc: true
    toc_depth: 2
---

# information about the dataset

## Goal of collecting this Dataset

Predicting Data Science job salaries using classification and clustering.

## The source of the dataset

Link to the source Dataset

<https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023?resource=download>

## Information about the Dataset

Number of Attributes: 11

Type of Attributes: nominal, ordinal, numeric

Number of objects: 3755

Class name: salary in usd

| Attributes names   | Description                                                                                 | Data type        | Possible values                                                                                                                  |
|------------------|------------------|------------------|-------------------|
| work_year          | The year the salary was paid                                                                | numirec          | Range between 2020-2023                                                                                                          |
| experience_level   | The experience level in the job during the year                                             | ordinal          | (SE:"Senior",MI:"Mid level",EN:"Entry level,EX:"Executive level")                                                                |
| employment_type    | The type of employment for the role                                                         | nominal          | (FT:"Full time",PT:"Part time",CT:"Contractual",FL:"Freelancer")                                                                 |
| job_title          | The role worked in during the year                                                          | nominal          | (Data Engineer, Data Scientist,Data Analyst, Machine Learning Engineer, Analytics Engineer...)It has 93 categories               |
| salary             | The total gross salary amount paid                                                          | numeric interval | Range Between [6000 - 30.4m]                                                                                                     |
| salary_currency    | The currency of the salary paid as an ISO 4217 currency code                                | nominal          | USD,EUR,GBP,INR,CAD...)                                                                                                          |
| salaryinusd        | The salary in USD                                                                           | numeric interval | Between[5132-450k]                                                                                                               |
| employee_residence | Employee's primary country of residence in during the work year as an ISO 3166 country code | nominal          | (US,GB,CA,ES,IN...)It has 78 categories                                                                                          |
| remote_ratio       | The overall amount of work done remotely                                                    | numeric Ratio    | (0, 50, 100)                                                                                                                     |
| company_location   | The country of the employer's main office or contracting branch                             | nominal          | (AE, AL, AM, AR. AS, AT, AU, BA BE, BO, BR, BS, CA, CF, CH, CL, CN, CO, CR, CZ, DE, DK, DZ, EE, EG,ES......)It has 72 categories |
| company_size       | The median number of people that worked for the company during the year                     | ordinal          | (S,M,L)                                                                                                                          |

## library used

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(magrittr)
```

## uploading the data and raw samples

raw data samples

```{r}
ds_salaries= read.csv(url("https://raw.githubusercontent.com/DeemAlshaye/Miningproject/main/dataset/ds_salaries.csv"), header=TRUE)
head(ds_salaries)
tail(ds_salaries)
```

```{r}
dim(ds_salaries)
```

# summarization and plotting

## summary the data

we used summary function to show each numeric value min, median, max, Q1 and Q3

```{r}
summary(ds_salaries)
```

## statical mesurment

Statistical measurements allows to explore our data in a quantitative manner,it helps to understand its distribution, variability, and key characteristics.

```{r}
mean(ds_salaries$salary)
median(ds_salaries$salary)
quantile(ds_salaries$salary)
```

we see that the mean is close to the median,and quantiles has high changes

```{r}
mean(ds_salaries$salary_in_usd)
median(ds_salaries$salary_in_usd)
quantile(ds_salaries$salary_in_usd)
```

we see that the mean is close to the median,and quantiles are close to one another.

```{r}
mean(ds_salaries$remote_ratio)
median(ds_salaries$remote_ratio)
quantile(ds_salaries$remote_ratio)
```

with only 3 valus for remote ratio we see a big diifrence between mean and median with the median being 0 wich means most work done was not onine and the quantile with the values 0 and 100 meaning there is really low number of work done half online half offline.

```{r}
mean(ds_salaries$work_year)
median(ds_salaries$work_year)
quantile(ds_salaries$work_year)
```

we see that the median is 2022 wich means that most pepole work year is 2022,and the quantile shows that the number of employee with work year 2020 are the least.

```{r}
var(ds_salaries$salary)
var(ds_salaries$salary_in_usd)
var(ds_salaries$remote_ratio)
var(ds_salaries$work_year)
```

we see that the var of salary is really high meaning higher risk var of salary in usd is also really high meaning higher risk the var of remote ratio is high but not quit high as salary and salary in usd meaning high risk work year var is low meaning lower risk

## changing the salary and salary in usd to be in 1000s

```{r}
ds_salaries$salary_1000s <- ds_salaries$salary /1000
head(ds_salaries$salary_1000s)

ds_salaries$salaryusd_1000s <- ds_salaries$salary_in_usd /1000
head(ds_salaries$salaryusd_1000s)
```

## graphs

we compared some variables with each other to find how they are distributed

#### boxplot:

```{r}
boxplot(ds_salaries$salary_1000s,ylim=c(0,1000),xlab="Salary",ylab="Salary in 1000s" ,main="boxplot of salary in 1000s")
```

Box plot represents salaries of employees,it displays the five number summary of the salary it shows that the salary has a lot of outliers that's need to be smoothed to remove the noise

```{r}
boxplot(ds_salaries$salaryusd_1000s,ylim=c(0,1000),xlab="Salary in USD",ylab="Salary in usd 1000s" ,main="boxplot of salary in usd in 1000s")
```

Box plot represents salary in (usd), it displays the five number summary of the salary in USD it shows that the salary in USD has a lot of outliers thats need to be smoothed to remove the noise

```{r}
boxplot(ds_salaries$work_year,xlab="Work year",ylab="Frequency"  ,main="boxplot of Work year")
```

Box plot represents work year (2020,2021,2022,2023), the work year box plot shows that there is a one outlier of 2020 year, that will be smoothed later to have more accurate data

### histogram

```{r}
hist(ds_salaries$salary_1000s,ylim=c(0,100),ylab="Frequency",xlab="salary in 1000s",main = "Salary Frequency")

```

The histogram represent the frequency of salaries for each employee, it shows that most of employees has small amount of salary

### bar plot

```{r}


ds_salaries$remote_ratio %>% table() %>% barplot(xlab="remote ratio", main="barplot of remote ratio")


ds_salaries$work_year %>% table() %>% barplot(xlab="work year", ylab="number of employees", main="barplot of work year")


  library(ggplot2)
library(tidyverse)
top_5_job_salaries<-ds_salaries%>%
  group_by(job_title)%>%
  summarise(Avg_Sal=mean(salary_1000s))%>%
  arrange(desc(Avg_Sal))%>%
  head()
top_5_job_salaries

```

First, the bar plot of 'remote ratio' represent the total of remote ratio for each employee, it show that most employees work on site then the employees who work online, the employees who work on both (online and onsite) have the smaller frequency

Second, the bar plot of 'work year' represent the work year and number of employee in each year, it show that 2020 year has the lowest number of employees, the number of employees increases annually

### Scatter plot

```{r}
  with(ds_salaries,plot(ds_salaries$salary_1000s,ds_salaries$salaryusd_1000s,xlab="salary in 1000s",ylab = "salary in usd 1000s",main="Scatter plot with salary and salary in USD") )
```

The scatter plot represents the correlation in salary and salary in usd, we notice that most of the salary and salary in usd are redundant data and the two attributes are strongly correlated

### pie chart

```{r}
library(dplyr)
ds_salaries2 <- ds_salaries %>% sample_n(50)

tab <- ds_salaries2$company_size%>% table()
precentages <- tab %>% prop.table() %>% round(3)*100
txt <- paste0(names(tab),'\n',precentages,'%')
pie(tab,labels=txt)

```

The pie chart represent the percentages for company size by taken sample of company, it shows that 2(Medium) has the highest frequency

### Visualisation

```{r}
ggplot(top_5_job_salaries, aes(x=job_title, y=Avg_Sal)) +
  geom_col() +
  labs(title="Top 5 Job Title Salaries", x="Job Title", y="Salary in 1000s") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

the bar plot of 'Top 5 job Title Salaries' represent the job title and the salary for each job, it shows that Head of Machine Learning has the highest salary

```{r}
ggplot(ds_salaries, aes(x=experience_level, y=salaryusd_1000s)) +
  geom_boxplot(fill="pink") +
  labs(title="Distribution of Salary by Experience Level", x="Experience Level", y="Salary in 1000s") +
  theme_minimal()
```

the box plot represent the percentages for experience level by taken sample of employees, it shows that salary aare different for each experience level, Also employees with the same experience level can have significantly higher salary than there category which can be observed from the box plot as outliers

## Average Salaries in each Year

```{r}
  library(dplyr)

yearly_salary_avg<-ds_salaries%>%
  group_by(work_year)%>%
  summarise(avg_salary=mean(salary_in_usd))
yearly_salary_avg
    
```

This table show the average salary increases annually for each year

# preprocessing

## Data cleaning

### categorizing job title

Categorize job title column

```{r}
library(tidyverse)
categorize_job_title <- function(title) {
  title <- tolower(title)
  if (grepl("data scientist|research scientist|researcher|scientist|science", title)) {
    return("Data Scientist")
  } else if (grepl("data engineer|etl|machine learning software engineer|ai|data architect|engineer|data modeler|machine learning engineer|devops", title)) {
    return("Data Engineer")
  } else if (grepl("data analyst|bi|analyst|head of data|data lead|data strategist|data analytics|specialist|data manager", title)) {
    return("Data Analyst")
  } else {
    return("Other")
  }
}
ds_salaries <- ds_salaries %>% 
  mutate(job_title = sapply(job_title, categorize_job_title))
head(ds_salaries)
```

Our column job title had 93 different categories, By using this categorization process, the code assigns each job title in the dataset to a general job title, we categorized the job title into four categorize ("Data Scientist","Data Engineer","Data Analyst",Other) , allowing for easier analysis and grouping of data based on their job title.

### Categorizing company location:

```{r}


# Define the country categories
asia <- c("AE", "CN", "HK", "ID", "IN", "JP", "KR", "MY", "PH", "SG", "TH", "TW", "VN")
europe <- c("AL", "AM", "AT", "BA", "BE", "BG", "BY", "CH", "CZ", "DE", "DK", "EE", "ES", "FI", "FR", "GB", "GE", "GR", "HR", "HU", "IE", "IL", "IT", "LT", "LU", "LV", "MD", "MK", "MT", "NL", "NO", "PL", "PT", "RO", "RS", "RU", "SE", "SI", "SK", "TR", "UA", 'ES')

north_america <- c("CA", "US")
south_america <- c("AR", "BO", "BR", "BS", "CL", "CO", "CR", "DO", "EC", "GT", "HN", "JM", "MX", "NI", "PA", "PE", "PY", "SV", "UY", "VE")
oceania <- c("AS", "AU", "FJ", "GU", "KI", "MH", "MP", "NC", "NF", "NZ", "PG", "PW", "SB", "TO", "TV", "VU", "WS")
africa <- c("BF", "BI", "BJ", "BW", "CD", "CG", "CI", "CM", "CV", "DJ", "DZ", "EG", "ET", "GA", "GH", "GM", "GN", "GQ", "KE", "LR", "LS", "LY", "MA", "MG", "ML", "MR", "MU", "MW", "MZ", "NA", "NE", "NG", "RE", "RW", "SC", "SD", "SH", "SL", "SN", "SO", "SS", "ST", "SZ", "TD", "TG", "TN", "TZ", "UG", "ZA", "ZM", "ZW")

# Function to categorize the company locations
categorize_location <- function(location) {
  if (location %in% asia) {
    return("Asia")
  } else if (location %in% europe) {
    return("Europe")
  } else if (location %in% north_america) {
    return("North America")
  } else if (location %in% south_america) {
    return("South America")
  } else if (location %in% oceania) {
    return("Oceania")
  } else if (location %in% africa) {
    return("Africa")
  } else {
    return("Other")
  }
}

# Apply the categorization to the company location column
ds_salaries$company_location <- sapply(ds_salaries$company_location,categorize_location)

# Print the updated dataset with categories
tail(ds_salaries)
```

Our column company location did have 72 different categories, By using this categorization process, the code assigns each company location in the dataset to a specific geographical region, such as Asia, Europe, North America, South America, Oceania, and Africa, allowing for easier analysis and grouping of data based on different regions of the world.

### finding missing data

we used is null function to show any null values in the dataset.

```{r}
sum(is.na(ds_salaries))
```

we did not have any missing values.

### finding outliers:

By detecting outliers, analysts can identify potential errors or anomalies in the data collection process, data entry, or measurement inaccuracies

```{r}
boxplot.stats(ds_salaries$salary)$out
boxplot.stats(ds_salaries$salary_in_usd)$out              
boxplot.stats(ds_salaries$remote_ratio)$out
boxplot.stats(ds_salaries$work_year)$out
```

We did detect the outliers in our numeric attributes

### Sum outliers:

```{r}
sum(boxplot.stats(ds_salaries$salary)$out)

sum(boxplot.stats(ds_salaries$salary_in_usd)$out)

sum(boxplot.stats(ds_salaries$remote_ratio)$out)

sum(boxplot.stats(ds_salaries$work_year)$out)
```

### removing the outliers:

Outliers can sometimes distort our analysis and models, so by removing them, we get a clearer picture of the data and can make better predictions or understand patterns more accurately

```{r}


library(dplyr)

# Remove outliers for each variable
ds_salaries <- ds_salaries %>%
  filter(
    between(salary, quantile(salary, 0.25) - 1.5 * IQR(salary), quantile(salary, 0.75) + 1.5 * IQR(salary)),
    between(salary_in_usd, quantile(salary_in_usd, 0.25) - 1.5 * IQR(salary_in_usd), quantile(salary_in_usd, 0.75) + 1.5 * IQR(salary_in_usd)),
    between(work_year, quantile(work_year, 0.25) - 1.5 * IQR(work_year), quantile(work_year, 0.75) + 1.5 * IQR(work_year))
  )

ds_salaries <- ds_salaries %>%
  filter(
    between(salary, quantile(salary, 0.25) - 1.5 * IQR(salary), quantile(salary, 0.75) + 1.5 * IQR(salary)),
    between(salary_in_usd, quantile(salary_in_usd, 0.25) - 1.5 * IQR(salary_in_usd), quantile(salary_in_usd, 0.75) + 1.5 * IQR(salary_in_usd)),
    between(work_year, quantile(work_year, 0.25) - 1.5 * IQR(work_year), quantile(work_year, 0.75) + 1.5 * IQR(work_year))
  )
```

We did this to make sure our data is more accurate and representative of the majority of the values.

## Data transformation

### Normalization

Normalizing data helps in improving the performance of machine learning models,reducing the training time and improving efficiency.

```{r}
normalize <- function(x) {return((x-min(x))/(max(x)-min(x)))}
ds_salaries$salary<-normalize(ds_salaries$salary)
ds_salaries$salary_in_usd<-normalize(ds_salaries$salary_in_usd)

num1_cols=ds_salaries[, c(5,7 )] 
head(num1_cols)
```

we normalized the attributes salary, salary in usd, so it takes values between 0 and 1 ,which helps in handling the data

### Discretization

transforming continuous data into categorical values.

```{r}


breaks <- quantile(ds_salaries$salary_in_usd, 
                   probs = c(0, 1/3, 2/3,1), 
                   na.rm = TRUE)

ds_salaries$salary_in_usd_disc <- cut(ds_salaries$salary_in_usd, 
                             breaks = breaks, 
                             include.lowest = TRUE, 
                             labels=c("low", "mid", "high"))
head(ds_salaries$salary_in_usd_disc)
                               
```

Discretization makes it easier to analyze and interpret the data

Encoding onverting categorical or ordinal variables into a numerical representation that can be used in data analysis and modeling. This transformation is necessary because many machine learning algorithms and statistical techniques require numerical inputs

### Encoding

```{r}
ds_salaries$company_size = factor(ds_salaries$company_size,levels = c("S","M","L"),labels = c(1,2,3))
ds_salaries$experience_level = factor(ds_salaries$experience_level,levels = c("EN","MI","SE","EX"),labels = c(1,2,3,4))

# Convert work_year to a categorical variable
ds_salaries$work_year <- factor(ds_salaries$work_year, levels = c(2021, 2022, 2023), labels = c("2021", "2022", "2023"))

# Convert remote_ratio to a categorical variable
ds_salaries$remote_ratio <- factor(ds_salaries$remote_ratio, levels = c(100, 50, 0), labels = c("100%", "50%", "0%"))

ds_salaries$job_title  <- factor(ds_salaries$job_title)
ds_salaries$employment_type  <- factor(ds_salaries$employment_type)
ds_salaries$employee_residence  <- factor(ds_salaries$employee_residence)
ds_salaries$company_location  <- factor(ds_salaries$company_location)
ds_salaries$salary_currency  <- factor(ds_salaries$salary_currency)


num_cols=ds_salaries[, c(2,11 )]
head(num_cols)
```

we encoded our ordinal and nominal variables using factor

## Removing irrelevant and duplicate attributes from the dataset

our data set has 2 salary coulombs salary, and salary in usd, for this, we will measure the correlation between them

```{r}

cor(ds_salaries$salary,ds_salaries$salary_in_usd)
```

we see that salary and salary_in_usd are highly correlated so we will only take the salary in USD.

we decided to remove employee resident due to its being irrelevant to our data sense the employee resident has nothing to do with his salary.

we also decided to remove salary currency sense we only took salary in USD.

```{r}
library(tidyverse)
ds_salaries <- ds_salaries %>%
  select(salary_in_usd_disc,work_year,experience_level,employment_type,job_title,company_location,company_size,remote_ratio)
  head(ds_salaries)
```

# Classification

The classification process involves dividing our dataset into training and testing subsets to build and evaluate machine learning models.that will predict the class lable(salary in usd) which has three classes:low,mid,and high,the prediction is made on the rest attributes, we will explore three different split ratios: 1- Training(80%) and Testing(20%) 2- Training(70%) and Testing(30%) 3- Training(90%) and Testing(10%), along with different decision tree algorithms that utilize the Gini index, Gain ratio, and Information gain as selection measures.

## checking if the data is balanced

```{r}
barplot(prop.table(table(ds_salaries$salary_in_usd_disc)),
        col = rainbow(2),
        ylim = c(0, 0.7),
        main = "Class Distribution")
```

```{r}
class_percentages <- prop.table(table(ds_salaries$salary_in_usd_disc)) * 100
print(class_percentages)
```

as shown in the bar plot above, and the class percentages, our class label is balanced, so we can split our data randomly without further steps.

## 1-Split the datasets into two subsets: Training(80%) and Testing(20%):

We chose this split because it helps Allocating 80% of the data for training provides a substantial amount of data for the model to learn from. With more training data, the model has a better chance of capturing the underlying patterns and relationships within the data, leading to improved performance. Setting aside 20% of the data for testing ensures that there is a sizable portion of unseen data available for evaluating the model's performance. Having a sufficient amount of testing data helps in obtaining reliable estimates of the model's accuracy and generalization ability.

```{r}
library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.8, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

```{r}
data_train <- create_train_test(ds_salaries, 0.8, train = TRUE)
data_test <- create_train_test(ds_salaries, 0.8, train = FALSE)
dim(data_train)
```

```{r}
dim(data_test)
```

The train dataset has 2837 rows while the test dataset has 710 rows.

we use the function prop.table() combined with table() to verify if the randomization process is correct.

```{r}
prop.table(table(data_train$salary_in_usd_disc))
```

```{r}
prop.table(table(data_test$salary_in_usd_disc))
```

### A-Decision Tree Using gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train, method = 'class')
rpart.plot(fit, extra = 100,type = 4)

```

### Interpreting visual representation of the tree for gini index

-   The model starts by checking the company location. If the company is located in Africa, Asia, Europe, Oceania, or South America, it predicts a low salary with a high probability.

-   If the company is located in North America, the model considers the job title. If the job title is "Data Analyst," it predicts a low salary with a higher probability. For other job titles like "Data Engineer," "Data Scientist," or "Other," the model predicts a high salary with a higher probability.

-   Within the "Data Engineer," "Data Scientist," or "Other, the model considers the experience level. If the experience level is 1 or 2, it predicts a mid salary with a high probability. If the experience level is 3 or 4, it predicts a high salary with a higher probability.

rpart() function uses the Gini impurity measure to split the note.

```{r}
predict_unseen <-predict(fit, data_test, type = 'class')
```

```{r}
result<-table(predict_unseen, data_test$salary_in_usd_disc)
co_result <- confusionMatrix(result)
print(co_result)
```

### Interpreting the results of Confusion Matrix and Statistics for gini index

The overall accuracy of the model is 55.77%. This means that the model correctly predicts the salary category for approximately 55.77% of the instances in the unseen dataset.

Sensitivity: - For the low salary category, the sensitivity is 70.15%, indicating that the model correctly identifies 70.15% of instances with low salaries. - For the mid salary category, the sensitivity is only 17.13%, suggesting that the model struggles to identify instances with mid-range salaries. - For the high salary category, the sensitivity is 77.51%, indicating good performance in identifying instances with high salaries.

Specificity:

-   For the low salary category, the specificity is 76.62%, meaning that the model accurately identifies instances that do not belong to the low salary category.
-   For the mid salary category, the specificity is 86.84%, indicating good performance in correctly identifying instances that do not belong to the mid salary category.
-   For the high salary category, the specificity is 70.61%, suggesting some difficulty in correctly identifying instances that do not belong to the high salary category.

Overall, the Gini Index shows moderate performance in predicting salary categories. It performs relatively well in identifying instances with high salaries, but struggles with instances in the mid salary range. The model achieves better accuracy for instances that do not belong to the low salary category compared to the mid and high salary categories.

precision: indicating the proportion of instances correctly predicted as a specific class compared to all instances predicted as that class. The positive predictive values for the "low," "mid," and "high" classes are 0.7170, 0.36275, and 0.4517, respectively.

### B-Decision Tree Using gain ratio

```{r}
library(C50)
library(printr)
library(caret)

```

Train decision tree

```{r}
model <- C5.0(salary_in_usd_disc ~., data=data_train)
```

Test

```{r}
results <- predict(model, data_test, type="class")

```

```{r}

plot(model, type="simple")
```

### Interpreting visual representation of the tree for gain ratio

-   The model starts by checking if the company location is in Africa, Asia, Europe, or Oceania. If so, it predicts a low salary with about 14.3% error.
-   If the company location is in North America, the model considers the employment type. If it's in "CT" or "FL" or "PT",it predicts a low salary with about 11.1% error.
-   If the employment type "FT" and job title is "Data Engineer" or "Data Scientist" or "other" the model looks at the experience level. For example, if it's 1 or 2 the model looks for remote ratio if it was 100%(which means online) or 50%(which means both on site and online), it predicts a low salary. for 0%(on site), it predicts a mid salary.
-   if the experience level was 3 or 4 it takes into account factors such as work year and remote work ratio and experience level to make predictions.

Overall, the model uses these factors to determine the most likely salary level within certain error rates for each prediction.

```{r}
library(caret)
result1<- table(results, data_test$salary_in_usd_disc)
co_result1 <- confusionMatrix(result1)
print(co_result1)
```

### Interpreting the results of Confusion Matrix and Statistics for gain ratio

the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.

Overall Accuracy: The overall accuracy of the model is 53.8%. This means that the model correctly predicts the salary category for approximately 53.8% of the instances in the dataset.

Sensitivity:

-   For the low salary category, the sensitivity is 80.31%, indicating that the model correctly identifies 80.31% of instances with low salaries.
-   For the mid salary category, the sensitivity is only 15.74%, suggesting that the model struggles to identify instances with mid-range salaries.
-   For the high salary category, the sensitivity is 51.48%, indicating a moderate performance in identifying instances with high salaries.

Specificity:

-   For the low salary category, the specificity is 65.19%, meaning that the model accurately identifies instances that do not belong to the low salary category.
-   For the mid salary category, the specificity is 82.79%, indicating good performance in correctly identifying instances that do not belong to the mid salary category.
-   For the high salary category, the specificity is 79.85%, suggesting some difficulty in correctly identifying instances that do not belong to the high salary category.

the precision values for the "low," "mid," and "high" classes are 0.7222, 0.5, and 0.5143, respectively.

Overall, the model shows moderate performance in predicting salary categories. It performs relatively well in identifying instances with low and high salaries but struggles with instances in the mid salary range. The model achieves better accuracy for instances that do not belong to the mid and high salary categories compared to the low salary category.

### C-Decision Tree Using information gain

```{r}
classify_dataset <- function(dataset, class_label) {
  # Load the required libraries
  library(rpart)
  library(rpart.plot)
  library(caret)

 


  # Create the decision tree model using information gain
  decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train, method = "class", control = rpart.control(cp = 0))

  # Plot the decision tree with reduced text and symbol size
  rpart.plot(decision_tree, extra = 100, cex = 0.5)
  
 # Predict on the test set
  predictions <- predict(decision_tree, newdata = data_test, type = "class")
  
  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)

}

classify_dataset(ds_salaries, "salary_in_usd_disc")

```

### Interpreting visual representation of the tree for information gain

we see that the tree starts by looking at the location of the company and determines that if it is in Africa, Asia, Europe, Oceania, or South America, the salary in usd is likely to be low. If the company is in North America, it further analyzes the job title and experience level to make a prediction. For example, if the job title is Data Analyst and the experience level is 1, the salary in usd is predicted to be low. The algorithm makes similar predictions for other job titles and experience levels, taking into account factors such as remote work opportunities and the year of work.experience level, and company size, Overall, the algorithm is trained to predict the salary in usd based on various input features, and these predictions are shown in the tree structure.

### Interpreting the results of Confusion Matrix and Statistics for information gain

-   The overall accuracy of the model is 53.38%. This means that the model correctly predicts the salary category for approximately 53.38% of the instances in the dataset.

Sensitivity:

-   For the low salary category, the sensitivity is 76.92%, indicating that the model correctly identifies 76.92% of instances with low salaries.
-   For the mid salary category, the sensitivity is 19.44%, suggesting that the model struggles to identify instances with mid-range salaries.
-   For the high salary category, the sensitivity is 51.48%, indicating a moderate performance in identifying instances with high salaries.

Specificity:

-   For the low salary category, the specificity is 72.99%, meaning that the model accurately identifies instances that do not belong to the low salary category.
-   For the mid salary category, the specificity is 78.95%, indicating good performance in correctly identifying instances that do not belong to the mid salary category.
-   For the high salary category, the specificity is 77.26%, suggesting some difficulty in correctly identifying instances that do not belong to the high salary category.

### Comparing and Interpreting the performance of the model using diffrent selection measures

The performance of the model was evaluated using three different selection measures: Gini index, Gain ratio, and Information gain.

In terms of accuracy, the Gini index measure achieved the highest accuracy rate of 55.77%, followed by Gain ratio with 53.8%, and Information gain with 53.38%. This indicates that the model's predictions aligned more closely with the actual salary categories when using the Gini index measure.

When considering balanced accuracy, which takes into account the performance across all classes, the Gini index measure outperformed the other two measures in most categories. It achieved a balanced accuracy of 73.39% for the low salary category, 74.06% for the high salary category, and 51.99% for the mid salary category. The Gain ratio and Information gain measures had relatively lower balanced accuracy scores in all categories.

the Gini index measure demonstrated better performance in most cases. It achieved higher sensitivity values for low (70.15%) and high (77.51%) salary categories compared to the other measures. However, it struggled with sensitivity for the mid salary category (17.13%). The Gini index measure also exhibited better specificity for the low (76.62%) and high (70.61%) salary categories. The Gain ratio and Information gain measures showed moderate sensitivity and specificity values across all salary categories.

In summary, the Gini index measure generally outperformed the Gain ratio and Information gain measures in terms of accuracy, balanced accuracy, Kappa, sensitivity, and specificity.

## 2-Split the Dataset into two subsets: Training(70%) and Testing(30%):

We chese this split because the 70% training and 30% testing split offers a significant portion of the dataset for training the model, enabling comprehensive learning and improved performance. The larger training set allows the model to better

```{r}


library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.7, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

```{r}
data_train70 <- create_train_test(ds_salaries, 0.7, train = TRUE)
data_test70 <- create_train_test(ds_salaries, 0.7, train = FALSE)
dim(data_train70)
```

```{r}
dim(data_test70)
```

The train set has 2482 rows while the test set has 1065 rows.

###A-Decision Tree Using gini index \### visual representation of the tree for gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train70, method = 'class')
rpart.plot(fit, extra = 100,type = 4)
```

### Interpreting visual representation of the tree for gini index

-   The model starts by checking the company location. If the company is located in Africa, Asia, Europe, Oceania, or South America, it predicts a low salary with a high probability.

-   If the company is located in North America, the model considers the job title. If the job title is "Data Analyst," it predicts a low salary with a higher probability. For other job titles like "Data Engineer," "Data Scientist," or "Other," the model predicts a high salary with a higher probability.

-   Within the "Data Engineer," "Data Scientist," or "Other, the model considers the experience level. If the experience level is 1 or 2, it predicts a mid salary with a higher probability. If the experience level is 3 or 4, it predicts a high salary with a higher probability.

rpart() function uses the Gini impurity measure to split the note.

```{r}
predict_unseen70 <-predict(fit, data_test70, type = 'class')
```

```{r}
table_mat70 <- table(data_test70$salary_in_usd_disc,predict_unseen70)
table_mat70
```

```{r}
accuracy_Test70 <- sum(diag(table_mat70)) / sum(table_mat70)
```

```{r}
print(paste('Accuracy for test', accuracy_Test70))
```

```{r}


result70_gini<-table(predict_unseen70, data_test70$salary_in_usd_disc)
co_result70_gini <- confusionMatrix(result70_gini)
print(co_result70_gini)
```

### Interpreting the results of Confusion Matrix and Statistics for gini index

the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.For example, the model predicted 299 instances as "low" when the true class was also "low," and it predicted 89 instances as "low" when the true class was "mid," and so on.

The overall accuracy of the model is 54.46%, meaning it correctly classified approximately 54.46% of the instances. The Kappa statistic suggests a fair agreement between the predicted and actual classes.

-   The "low" class has a sensitivity of 67.49%, specificity of 81.67%, and positive predictive value of 72.40%.
-   The "mid" class has a sensitivity of 12.35%, specificity of 88.41%, and positive predictive value of 33.33%.
-   The "high" class has a sensitivity of 84.75%, specificity of 63.35%, and positive predictive value of 45.44%.
-   The negative predictive value is relatively high for all classes, indicating a good ability to correctly identify negative instances.
-   the precision values for the "low," "mid," and "high" classes are 0.7703, 0.3896, and 0.5330, respectively.

### B-Decision Tree Using gain ratio

Applying Decision trees classification using gain ratio selection measure

```{r}
library(C50)
library(printr)
model70 <- C5.0(salary_in_usd_disc ~., data=data_train70)
```

Make predictions on the test data

```{r}
results70_gain <- predict(object=model70, newdata=data_test70, type="class")

```

```{r}
plot(model70, type="simple")
```

### Interpreting visual representation of the tree for gain ratio

-   The model starts by checking if the company location is in Africa, Asia, Europe, or Oceania. If so, it predicts a low salary with about 14.6% error.
-   If the company location is in North America, the model considers the job title. If it's in "Data Analyst" or other, the model predicts a low salary with an 51.9% error.
-   If the job title is "Data Engineer" or "Data Scientist", the model looks at the experience level. For example, if it's 3 or 4 the model looks for remote ratio if it was 100%(which means online), it predicts a high salary. for 50%(which means both on site and online), it predicts a mid salary with a 0.0% error, for the 0%(on site), it takes work year into concider.
-   if the experience level was 1 or 2 it takes into account factors such as employment type and remote work ratio and experience level to make predictions.

Overall, the model uses these factors to determine the most likely salary level within certain error rates for each prediction.

Confusion Matrix and Statistics

```{r}
result70<-table(results70_gain, data_test70$salary_in_usd_disc)
co_result70_gain <- confusionMatrix(result70)
print(co_result70_gain)
```

### Interpreting the results of Confusion Matrix and Statistics for gain ratio

the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.

The overall accuracy of the model is 53.24%, indicating that it correctly classified approximately 53.24% of the instances. The 95% confidence interval suggests that the true accuracy of the model falls between 0.5019 and 0.5627.

The performance measures for each class are as follows:

-   For the "low" class:

Sensitivity: 71.11% Specificity: 80.23% Positive Predictive Value: 71.92%

-   For the "mid" class:

Sensitivity: 28.23% Specificity: 76.28% Positive Predictive Value: 35.82%

-   For the "high" class:

Sensitivity: 55.32% Specificity: 74.07% Positive Predictive Value: 43.45%

the model shows varying performance for different classes. The highest accuracy is achieved for the "low" class, while the "mid" class has the lowest accuracy.

### C-Decision Tree Using information gain

```{r}
classify_dataset <- function(dataset, class_label) {



decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train70, method = "class", control = rpart.control(cp = 0))


  rpart.plot(decision_tree, extra = 100, cex = 0.5)
 
  predictions <- predict(decision_tree, newdata = data_test70, type = "class")

  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test70[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)
}

classify_dataset(ds_salaries, "salary_in_usd_disc")
```

### Interpreting visual representation of the tree for information gain

we see that the tree starts by looking at the location of the company and determines that if it is in Africa, Asia, Europe, Oceania, or South America, the salary in usd is likely to be low. If the company is in North America or Other, it further analyzes the job title and experience level to make a prediction. For example, if the job title is Data Analyst and the experience level is 1, the salary in usd is predicted to be low. The algorithm makes similar predictions for other job titles and experience levels, taking into account factors such as remote work opportunities and the year of work.experience level, and company size, Overall, the algorithm is trained to predict the salary in usd based on various input features, and these predictions are shown in the tree structure.

### Interpreting the results of Confusion Matrix and Statistics for information gain

The overall accuracy of the model is 53.8%. This means that the model correctly classified approximately 53.8% of the instances in the dataset.

The 95% confidence interval (CI) for accuracy ranges from 0.5075 to 0.5683. This interval provides a range of values within which we can be 95% confident that the true accuracy of the model lies.

The sensitivity values for each salary category:

For the "low" salary category: The model correctly identifies 59.37% of instances with low salaries. For the "mid" salary category: The model correctly identifies 44.12% of instances with mid-range salaries. For the "high" salary category: The model correctly identifies 56.74% of instances with high salaries.

The specificity values for each non-salary category:

For non-"low" salaries: The model correctly identifies 91.32% of instances with non-low salaries. For non-"mid" salaries: The model correctly identifies 67.03% of instances with non-mid salaries. For non-"high" salaries: The model correctly identifies 74.58% of instances with non-high salaries.

The Precisions, for the "low," "mid," and "high" classes are 0.8595, 0.5747, and 0.5212, respectively.

### Comparing and Interpreting the performance of the model using diffrent selection measures

-   In terms of accuracy, all three measures show similar performance, ranging from 53.24% to 54.46%. However, the Gini Index has the highest accuracy of 54.46% among the three.

-   Balanced accuracy measures the average performance across classes, and here the Gini Index has the highest balanced accuracy for both the low and high classes.

-   Kappa indicates the agreement between predicted and actual classes, and the Gini Index has the highest Kappa value among the three measures.

-   Sensitivity and specificity measure the ability to correctly identify instances within a class and instances that do not belong to a class, respectively. The Information Gain measure has the highest sensitivity for the low class, while the Gini Index has the highest sensitivity for the high class. The Gini Index has the highest specificity for the low class, while the Gain Ratio has the highest specificity for the mid class.

-   Mcnemar's Test P-Value indicates the statistical significance of the difference between the measures. In all cases, the p-values are very low, suggesting significant differences between the measures.

-   Overall, the Gini Index performs slightly better than the other two measures in terms of accuracy, balanced accuracy, and kappa.

## 3-Split the datasets into two subsets: Training(90%) and Testing(10%):

we choose this partition sense more training data often leads to better model performance ,By reserving a smaller portion for testing, we reduce the risk of over-fitting to the test set.

### Create train/test function

```{r}
library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.9, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

### using the train/test function

```{r}
data_train <- create_train_test(ds_salaries, 0.9, train = TRUE)
data_test <- create_train_test(ds_salaries, 0.9, train = FALSE)
dim(data_train)
```

```{r}
dim(data_test)
```

we see that The train dataset has 3192 rows while the test dataset has 355 rows.

### gini index

Applying Decision trees classification using gini index selection measure

### visual representation of the tree for gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train, method = 'class')
rpart.plot(fit, extra = 100,type = 4)

# Plot the tree with a simple text representation
print(fit)

# Generate rules from the decision tree
rules <- rpart.rules(fit)

# Print the rules
print(rules)

```

### Interpreting visual representation of the tree for gini index

-   The model starts by checking the company location. If the company is located in Africa, Asia, Europe, Oceania, or South America, it predicts a low salary with a high probability.

-   If the company is located in North America or Other, the model considers the job title. If the job title is "Data Analyst," it predicts a low salary with a higher probability. For other job titles like "Data Engineer," "Data Scientist," or "Other," the model predicts a high salary with a higher probability.

-   Within the "Data Analyst" category, the model considers the experience level. If the experience level is 1 or 2, it predicts a mid salary with a higher probability. If the experience level is 3 or 4, it predicts a high salary with a higher probability.

```{r}
predict_unseen <-predict(fit, data_test, type = 'class')
```

```{r}
result<-table(predict_unseen, data_test$salary_in_usd_disc)
co_result <- confusionMatrix(result)
print(co_result)
```

### Interpreting the results of Confusion Matrix and Statistics for gini index

In a simple way, the confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high). The precision values indicate the proportion of correct predictions for each class.

-   For the "low" salary level, the model predicts it correctly 68.78% of the time. The model has a specificity of 75.30%, meaning it correctly identifies non-low salaries 75.30% of the time.
-   For the "mid" salary level, the accuracy is lower, with the model predicting it correctly 23.66% of the time. The specificity for this class is 80.92%.
-   For the "high" salary level, the model predicts it correctly 71.23% of the time. The specificity for this class is 78.72%.

Overall, the accuracy of the model is 57.46%, meaning it predicts the correct salary level about 57.46% of the time. The Kappa value measures the level of agreement between the model's predictions and the actual salary levels, which is 0.32 indicating a fair level of agreement.

### gain ratio

Applying Decision trees classification using gain ratio selection measure

```{r}
library(C50)
library(printr)
library(caret)

```

### visual representation of the tree for gain ratio

```{r}
library(C50)
library(partykit)
library(rpart.plot)
library(rpart)
library(rpart.plot)

model <- C5.0(salary_in_usd_disc ~., data=data_train)
party_model <- as.party(model)



# Plot the tree using default plotting method
plot(party_model,type="simple")



# Plot the tree with a simple text representation
print(party_model)
```

### Interpreting visual representation of the tree for gain ratio

-   The model starts by checking if the company location is in Africa, Asia, Europe, or Oceania. If so, it predicts a low salary with about 13.6% error.
-   If the company location is in North America or Other, the model considers the employment type. If it's in CT, FL, or PT, it predicts a low salary with an 8.3% error.
-   If the employment type is FT, the model looks at the job title. For example, if it's a Data Analyst, it predicts a low salary with a 52.5% error. For other job titles like Data Engineer or Data Scientist, it considers the experience level.
-   Based on the experience level, the model predicts either a mid or high salary with specific errors.
-   The model also takes into account factors such as remote work ratio and work year to make predictions.

Overall, the model uses these factors to determine the most likely salary level within certain error rates for each prediction.

```{r}
results <- predict(model, data_test, type="class")

```

```{r}
library(caret)
result1<- table(results, data_test$salary_in_usd_disc)
co_result1 <- confusionMatrix(result1)
print(co_result1)
```

### Interpreting the results of Confusion Matrix and Statistics for gain ratio

In a simple way, the results show how well the algorithm predicts salary levels based on different factors. The confusion matrix displays the number of correct and incorrect predictions for each salary level (low, mid, high).

Overall, the accuracy of the model is 60.28%, meaning it predicts the correct salary level about 60.28% of the time. The Kappa value indicates a fair level of agreement between the model's predictions and the actual salary levels.

When looking at individual salary levels: - For low salaries, the algorithm correctly predicts them 76.72% of the time. - For mid salaries, the algorithm has a lower accuracy, correctly predicting them 22.58% of the time. - For high salaries, the accuracy of the model is 65.75%.

The specificity measures how well the model predicts non-target classes. - For lowl salaries, the model correctly identifies non-low salaries 72.29% of the time. - For mid salaries, the model identifies non-mid salaries with a specificity of 84.73%. - For high salaries, the specificity is 80.50%.

In general, the model performs better at predicting non-low and non-mid salaries compared to predicting the exact salary level.

### information gain

Applying Decision trees classification using information gain selection measure

### visual representation of the tree for information gain

```{r}
classify_dataset <- function(dataset, class_label) {
  # Load the required libraries
  library(rpart)
  library(rpart.plot)
  library(caret)

 


  # Create the decision tree model using information gain
  decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train, method = "class", control = rpart.control(cp = 0))

  # Plot the decision tree with reduced text and symbol size
  rpart.plot(decision_tree, extra = 100, cex = 0.5)
  



 # Predict on the test set
  predictions <- predict(decision_tree, newdata = data_test, type = "class")
  
  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)
  

}

classify_dataset(ds_salaries, "salary_in_usd_disc")

```

### Interpreting the results of Confusion Matrix and Statistics for information gain

The confusion matrix and statistics provide information about how well the decision tree model performs in classifying salary in usd. Let's break down the important details:

Overall Accuracy: The model's accuracy is 59.44%, meaning it correctly predicts salary in usd about 59.44% of the time.

Kappa: The model's agreement with the actual salary in usd is fair, with a Kappa value of 0.3545.

McNemar's Test: There is a significant difference in the predictions made by the model for different salary in usd.

Sensitivity: The model correctly identifies 70.37% of low salary in usd , 35.48% of mid salary in usd, and 61.64% of high salary in usd.

Specificity: The model correctly identifies 80.72% of non-low salary in usd, 78.63% of non-mid salary in usd, and 80.14% of non-high salary in usd.

Positive Predictive Value: When the model predicts a salary in usd as low, it is right 80.61% of the time. For mid salary in usd, it is right 37.08% of the time, and for high salary in usd, it is right 44.55% of the time.

Negative Predictive Value: When the model predicts a salary in usd as non-low, it is right 70.53% of the time. For non-mid salary in usd, it is right 77.44% of the time, and for non-high salary in usd, it is right 88.98% of the time.

Balanced Accuracy: On average, the model's performance is around 75.55% for low salary in usd, 57.06% for mid salary in usd, and 70.89% for high salary in usd.

### Interpreting visual representation of the tree for information gain

we see that the tree starts by looking at the location of the company and determines that if it is in Africa, Asia, Europe, Oceania, or South America, the salary in usd is likely to be low. If the company is in North America or Other, it further analyzes the job title and experience level to make a prediction. For example, if the job title is Data Analyst and the experience level is 1, the salary in usd is predicted to be low. The algorithm makes similar predictions for other job titles and experience levels, taking into account factors such as remote work opportunities and the year of work. Overall, the algorithm is trained to predict the salary in usd based on various input features, and these predictions are shown in the tree structure.

### Comparing and Interpreting the performance of the model using diffrent selection measures

Accuracy: Gain Ratio achieved the highest accuracy (60.28%), followed by Information Gain (59.44%) and Gini Index (57.46%).

Balanced Accuracy: Gain Ratio also performed well in terms of balanced accuracy across classes. Information Gain and Gini Index were comparable but slightly lower.

Kappa: Information Gain had the highest Kappa value (0.3545), indicating a moderate level of agreement. Gain Ratio and Gini Index had slightly lower Kappa values (0.3477 and 0.32, respectively).

Sensitivity and Specificity: The performance across sensitivity and specificity varied for different classes. Gain Ratio tended to have a higher sensitivity for the low class, while Gini Index performed better for the high class.

McNemar's Test P-Value: This test assesses whether the differences in performance are statistically significant. In all cases, the p-values are quite small, suggesting that the differences are statistically significant.

-   Gain Ratio seems to be the most balanced attribute selection measure in terms of accuracy and balanced accuracy.

-   Information Gain provides the highest accuracy but with slightly lower balanced accuracy compared to Gain Ratio.

-   Gini Index, while providing competitive results, tends to have slightly lower accuracy and balanced accuracy compared to Information Gain and Gain Ratio.

## comparing between the three splits(90:10,80:20,70:30)

In this classification study, we aimed to evaluate the performance of three different attribute selection measures on our dataset using three different splits. The attribute selection measures considered were the Gini index, Gain ratio, and Information gain. The dataset was divided into three subsets using the 90:10 split, 80:20 split, and 70:30 split. After analyzing the results, we found that the best model was obtained using the 90:10 split,and the gain ratio attribute selection measure.which provided a moderate level of accuracy in classifying instances into low, mid, and high salary categories.

-   The overall accuracy of the model is 0.6028, indicating that 60.28% of the instances were correctly classified.
-   The sensitivity, or true positive rate, for the low, mid, and high salary categories are 0.7672, 0.22581, and 0.6575, respectively.
-   The specificity, or true negative rate, for the low, mid, and high salary categories are 0.7229, 0.84733, and 0.8050, respectively.

# Clustering

clustering the data set based on the number of k that represent number of clusters without knowing the class label (unsupervised learning)

```{r}
#sbset of original dataset
ds_salaries_clustering<-ds_salaries
#delete the class label from sebset dataset before running the cluster algorithm
classLable<-(ds_salaries$salary_in_usd_disc)
ds_salaries_clustering <- subset(ds_salaries_clustering,select=-c(salary_in_usd_disc))
```

we made a subset of the original dataset to ds_salaries_clustering to to clustering on the subset dataset

#### change the value of attribute from factor to numeric

```{r}
ds_salaries_clustering$experience_level <- as.numeric(ds_salaries_clustering$experience_level)
ds_salaries_clustering$company_location <- as.numeric(ds_salaries_clustering$company_location)
ds_salaries_clustering$employment_type  <- as.numeric(ds_salaries_clustering$employment_type)
ds_salaries_clustering$company_size <- as.numeric(ds_salaries_clustering$company_size)
ds_salaries_clustering$job_title <- as.numeric(ds_salaries_clustering$job_title)
ds_salaries_clustering$remote_ratio <- as.numeric(ds_salaries_clustering$remote_ratio)
ds_salaries_clustering$work_year <- as.numeric(ds_salaries_clustering$work_year)
```

changing the factors and categorical values to numeric values to facilitate the clustering

**summary the data after transferring to numerical values**

```{r}
summary(ds_salaries_clustering)
str(ds_salaries_clustering)
```

**Scaling the data**

```{r}
# Scaling the data
ds_salaries_clustering=scale(ds_salaries_clustering)
```

## perform K-means clustering

We used the K-means algorithm with varying values of 3 K for clustering, aiming to determine the optimal number of clusters. We computed the average silhouette width for each K, leading to the following conclusions:

```{r}
perform_kmeans <- function(data, k) {
  set.seed(200) 
  #we choose different number of k (number of clusters) to be the center
  kmeans_result <- kmeans(data, centers = k, nstart = 25)
  return(kmeans_result)
}
```

## different number of clusters:

## k=2

```{r}
library(factoextra)
library(cluster)
set.seed(200)
# Perform k-means clustering
k <- 2
kmeans_result <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)
```

We choose k=2 through visual examination, as it produced the most well-defined clusters without depending on formal validation techniques. The dataset clusters showed clear and easily distinguishable clusters.

- Cluster 1 has a size of 3166 and an average silhouette width of 0.39. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
- Cluster 2 has a size of 385 and an average silhouette width of 0.17. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.

The average silhouette width for k= 2 is equal to 0.37 have the highest value which it highst number of clustering that close to number 1 and we can cluster the data based on it


## k=3

```{r}
set.seed(900)

# Perform k-means clustering
k <- 3
kmeans_result <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)

```

k=3 is grounded in our observations, specifically guided by the Elbow method. Through this method, we identified k = 3 as the value nearest to the elbow point in the variation plot. This choice proves effective in dividing the dataset into clusters, yielding well-defined and distinct groupings.

- Cluster 1 has a size of 1411 and an average silhouette width of 0.19. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
- Cluster 2 has a size of 379 and an average silhouette width of 0.14. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.
- Cluster 3 has a size of 1761 and an average silhouette width of 0.36. This indicates that the data points within Cluster 3 are relatively well-matched and separated from other clusters, similar to Cluster 1.

Overall, the results show that Cluster 1 and Cluster 3 have a higher quality in terms of clustering structure and separation, while Cluster 2 may have some overlapping data points or a less distinct clustering pattern.

The average silhouette width for k= 3 is equal to 0.27 have the lowest value for all of the clusters


## k=10

```{r}
set.seed(8203)
# Perform k-means clustering
k <- 10
kmeans_result <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)
```

We initially selected k=10 based on observations using the silhouette coefficient method, aiming for well-separated clusters where objects within the same cluster are close to each other. According to the silhouette coefficient, optimal clustering should yield values between zero and one. However, the actual clustering results did not align with our expectations. The quality of the clusters is considered poor, contradicting the anticipated characteristics. Therefore, k=10 may not be the optimal representation for clustering our dataset.


- Cluster 1 has a size of 1287 and an average silhouette width of 0.36. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
- Cluster 2 has a size of 156 and an average silhouette width of 0.14. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.
- Cluster 3 has a size of 203 and an average silhouette width of 0.09. This indicates that the data points within Cluster 3 are less well-separated compared to Cluster 1 and 2, with potentially more overlap or ambiguity.
- Cluster 4 has a size of 41 and an average silhouette width of 0.41. This suggests that the data points within Cluster 4 are relatively well-separated and distinct from other clusters.
- Cluster 5, 6, 7, 8, 9, and 10 also have their respective sizes and average silhouette widths.

Overall, the results show that different clusters have varying levels of quality in terms of clustering structure and separation. Clusters 1, 4, 9, and 10 seem to have relatively higher quality with well-separated data points, while Clusters 3 and 7 have lower silhouette widths and potentially more 


The average silhouette width for k= 10 is equal to 0.32 have the middle value which it between k=2 and k= 3


## Validation

we applied multiple validation methods for our clustering process, and we aim to validate the appropriate number of k for each cluster .

#### Elbow method

```{r}
library(factoextra) 
fviz_nbclust(ds_salaries_clustering, kmeans, method = "wss") + geom_vline(xintercept= 3, linetype= 2)+
labs(subtitle = "Elbow method")
```

we use the elbow method to determine the right number of clusters for our dataset by using the turning point in the curve to determine the number of clusters that was equal to 3.

#### Silhouette method

```{r}
fviz_nbclust(ds_salaries_clustering, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
```

We use silhouette coefficient (extrinsic method) method to calculate the optimal number of k which k represent the number of clusters and then we observed that the optimal number of clusters to classify our data set that has a highest value and close to number 1 is equal to 10.

#### Total within-cluster sum of square

```{r}
total_wss <- kmeans_result$tot.withinss
print(total_wss)
```

Total within-cluster sum of square represents the sum of square distances between every point in the dataset it is defined how close the points are "within the cluster" and here the value=9655.23 represent how tight the point in the same cluster are.

#### BCubed precision and recall

```{r}
# Define k_means_clustering function
k_means_clustering <- function(data, k) {
  k_means_result <- kmeans(data, centers = k)  # Perform k-means clustering
  return(k_means_result$cluster)  # Return cluster assignments
}

# Example usage
selected_data <- ds_salaries_clustering  # Use the entire dataset
k <- 3  # Number of clusters
cluster_assignments <- k_means_clustering(selected_data, k)

# Convert cluster assignments to integer codes
cluster_codes <- as.integer(cluster_assignments)

# Add cluster assignments to the selected data
selected_data$Cluster <- as.factor(cluster_codes)

# Corrected B-Cubed metrics calculation for k-means
bcubed_precision_recall <- function(labels_true, labels_pred) {
  labels_true <- as.factor(labels_true)
  labels_pred <- as.factor(labels_pred)
  
  unique_labels <- unique(labels_true)
  num_points <- length(labels_true)
  
  precision_sum <- 0
  recall_sum <- 0
  
  for (true_label in unique_labels) {
    true_indices <- labels_true == true_label
    pred_labels <- labels_pred[true_indices]
    
    unique_pred_labels <- unique(pred_labels)
    
    for (pred_label in unique_pred_labels) {
      common_points <- sum(pred_labels == pred_label)
      precision_sum <- precision_sum + common_points / sum(labels_pred == pred_label)
      recall_sum <- recall_sum + common_points / sum(labels_true == true_label)
    }
  }
  
  precision <- precision_sum / num_points
  recall <- recall_sum / num_points
  
  return(list(precision = precision, recall = recall))
}

precision_recall <- bcubed_precision_recall(selected_data$Cluster, cluster_codes)
precision <- precision_recall$precision
recall <- precision_recall$recall

print(paste("B-Cubed Precision:", precision))
print(paste("B-Cubed Recall:", recall))

```

## Clustering Findings

#### Finally we find that the clustering method is not working successfully for our data set because when we use the optimal number of k that equal to 10 the model for this cluster have an overlap for the clusters.

#### Previously we know that the clusters in clustering method should be far from each other and the objects inside each cluster should be close to the center for the cluster but here in the optimal number of k equal to 10 that opposite of that role is happening.

#### So we can say the 10 is a bad number of k to cluster our dataset because the clusters is very close to each other and the objects inside each cluster is far from the center.

#### So we assume that the classification method for our dataset is classify and divide the dataset successfully and useful more than clustering , so we just need to do a classification and don't need to cluster the dataset.
