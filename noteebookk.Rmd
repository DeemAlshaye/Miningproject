---
title: "Data Salaries"
output:
  html_document:
    toc: true
    toc_depth: 2
---

# Problem

# Data Mining task

# Data

## Goal of collecting this Dataset

Predicting Data Science job salaries using classification and clustering.

## The source of the dataset

Link to the source Dataset

<https://www.kaggle.com/datasets/arnabchaki/data-science-salaries-2023?resource=download>

## Information about the Dataset

Number of Attributes: 11

Type of Attributes: nominal, ordinal, numeric

Number of objects: 3755

Class name: salary in usd

+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| Attributes names   | Description                                                                                 | Data type        | Possible values                                                                                                                  |
+====================+=============================================================================================+==================+==================================================================================================================================+
| work_year          | The year the salary was paid                                                                | numirec          | Range between 2020-2023                                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| experience_level   | The experience level in the job during the year                                             | ordinal          | (SE:"Senior",MI:"Mid level",EN:"Entry level,EX:"Executive level")                                                                |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| employment_type    | The type of employment for the role                                                         | nominal          | (FT:"Full time",PT:"Part time",CT:"Contractual",FL:"Freelancer")                                                                 |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| job_title          | The role worked in during the year                                                          | nominal          | (Data Engineer, Data Scientist,Data Analyst, Machine Learning Engineer, Analytics Engineer...)It has 93 categories               |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| salary             | The total gross salary amount paid                                                          | numeric interval | Range Between [6000 - 30.4m]                                                                                                     |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| salary_currency    | The currency of the salary paid as an ISO 4217 currency code                                | nominal          | USD,EUR,GBP,INR,CAD...)                                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| salaryinusd        | The salary in USD                                                                           | numeric interval | Between[5132-450k]                                                                                                               |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| employee_residence | Employee's primary country of residence in during the work year as an ISO 3166 country code | nominal          | (US,GB,CA,ES,IN...)It has 78 categories                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| remote_ratio       | The overall amount of work done remotely                                                    | numeric Ratio    | (0, 50, 100)                                                                                                                     |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| company_location   | The country of the employer's main office or contracting branch                             | nominal          | (AE, AL, AM, AR. AS, AT, AU, BA BE, BO, BR, BS, CA, CF, CH, CL, CN, CO, CR, CZ, DE, DK, DZ, EE, EG,ES......)It has 72 categories |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+
| company_size       | The median number of people that worked for the company during the year                     | ordinal          | (S,M,L)                                                                                                                          |
+--------------------+---------------------------------------------------------------------------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------+

## library used

```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(magrittr)
```

## uploading the data and raw samples

raw data samples

```{r}
ds_salaries= read.csv(url("https://raw.githubusercontent.com/DeemAlshaye/Miningproject/main/dataset/ds_salaries.csv"), header=TRUE)
head(ds_salaries)
tail(ds_salaries)
```

```{r}
dim(ds_salaries)
```

## summarization and plotting

## summary the data

we used summary function to show each numeric value min, median, max, Q1 and Q3

```{r}
summary(ds_salaries)
```

## statical mesurment

Statistical measurements allows to explore our data in a quantitative manner,it helps to understand its distribution, variability, and key characteristics.

```{r}
mean(ds_salaries$salary)
median(ds_salaries$salary)
quantile(ds_salaries$salary)
```

we see that the mean is close to the median,and quantiles has high changes

```{r}
mean(ds_salaries$salary_in_usd)
median(ds_salaries$salary_in_usd)
quantile(ds_salaries$salary_in_usd)
```

we see that the mean is close to the median,and quantiles are close to one another.

```{r}
mean(ds_salaries$remote_ratio)
median(ds_salaries$remote_ratio)
quantile(ds_salaries$remote_ratio)
```

with only 3 valus for remote ratio we see a big diifrence between mean and median with the median being 0 wich means most work done was not onine and the quantile with the values 0 and 100 meaning there is really low number of work done half online half offline.

```{r}
mean(ds_salaries$work_year)
median(ds_salaries$work_year)
quantile(ds_salaries$work_year)
```

we see that the median is 2022 wich means that most pepole work year is 2022,and the quantile shows that the number of employee with work year 2020 are the least.

```{r}
var(ds_salaries$salary)
var(ds_salaries$salary_in_usd)
var(ds_salaries$remote_ratio)
var(ds_salaries$work_year)
```

we see that the var of salary is really high meaning higher risk var of salary in usd is also really high meaning higher risk the var of remote ratio is high but not quit high as salary and salary in usd meaning high risk work year var is low meaning lower risk

## changing the salary and salary in usd to be in 1000s

```{r}
ds_salaries$salary_1000s <- ds_salaries$salary /1000
head(ds_salaries$salary_1000s)

ds_salaries$salaryusd_1000s <- ds_salaries$salary_in_usd /1000
head(ds_salaries$salaryusd_1000s)
```

## graphs

we compared some variables with each other to find how they are distributed

#### boxplot:

```{r}
boxplot(ds_salaries$salary_1000s,ylim=c(0,1000),xlab="Salary",ylab="Salary in 1000s" ,main="boxplot of salary in 1000s")
```

Box plot represents salaries of employees,it displays the five number summary of the salary it shows that the salary has a lot of outliers that's need to be smoothed to remove the noise

```{r}
boxplot(ds_salaries$salaryusd_1000s,ylim=c(0,1000),xlab="Salary in USD",ylab="Salary in usd 1000s" ,main="boxplot of salary in usd in 1000s")
```

Box plot represents salary in (usd), it displays the five number summary of the salary in USD it shows that the salary in USD has a lot of outliers thats need to be smoothed to remove the noise

```{r}
boxplot(ds_salaries$work_year,xlab="Work year",ylab="Frequency"  ,main="boxplot of Work year")
```

Box plot represents work year (2020,2021,2022,2023), the work year box plot shows that there is a one outlier of 2020 year, that will be smoothed later to have more accurate data

### histogram

```{r}
hist(ds_salaries$salary_1000s,ylim=c(0,100),ylab="Frequency",xlab="salary in 1000s",main = "Salary Frequency")

```

The histogram represent the frequency of salaries for each employee, it shows that most of employees has small amount of salary

### bar plot

```{r}


ds_salaries$remote_ratio %>% table() %>% barplot(xlab="remote ratio", main="barplot of remote ratio")


ds_salaries$work_year %>% table() %>% barplot(xlab="work year", ylab="number of employees", main="barplot of work year")


  library(ggplot2)
library(tidyverse)
top_5_job_salaries<-ds_salaries%>%
  group_by(job_title)%>%
  summarise(Avg_Sal=mean(salary_1000s))%>%
  arrange(desc(Avg_Sal))%>%
  head()
top_5_job_salaries

```

First, the bar plot of 'remote ratio' represent the total of remote ratio for each employee, it show that most employees work on site then the employees who work online, the employees who work on both (online and onsite) have the smaller frequency

Second, the bar plot of 'work year' represent the work year and number of employee in each year, it show that 2020 year has the lowest number of employees, the number of employees increases annually

### Scatter plot

```{r}
  with(ds_salaries,plot(ds_salaries$salary_1000s,ds_salaries$salaryusd_1000s,xlab="salary in 1000s",ylab = "salary in usd 1000s",main="Scatter plot with salary and salary in USD") )
```

The scatter plot represents the correlation in salary and salary in usd, we notice that most of the salary and salary in usd are redundant data and the two attributes are strongly correlated

### pie chart

```{r}
library(dplyr)
ds_salaries2 <- ds_salaries %>% sample_n(50)

tab <- ds_salaries2$company_size%>% table()
precentages <- tab %>% prop.table() %>% round(3)*100
txt <- paste0(names(tab),'\n',precentages,'%')
pie(tab,labels=txt)

```

The pie chart represent the percentages for company size by taken sample of company, it shows that 2(Medium) has the highest frequency

### Visualisation

```{r}
ggplot(top_5_job_salaries, aes(x=job_title, y=Avg_Sal)) +
  geom_col() +
  labs(title="Top 5 Job Title Salaries", x="Job Title", y="Salary in 1000s") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

the bar plot of 'Top 5 job Title Salaries' represent the job title and the salary for each job, it shows that Head of Machine Learning has the highest salary

```{r}
ggplot(ds_salaries, aes(x=experience_level, y=salaryusd_1000s)) +
  geom_boxplot(fill="pink") +
  labs(title="Distribution of Salary by Experience Level", x="Experience Level", y="Salary in 1000s") +
  theme_minimal()
```

the box plot represent the percentages for experience level by taken sample of employees, it shows that salary aare different for each experience level, Also employees with the same experience level can have significantly higher salary than there category which can be observed from the box plot as outliers

## Average Salaries in each Year

```{r}
  library(dplyr)

yearly_salary_avg<-ds_salaries%>%
  group_by(work_year)%>%
  summarise(avg_salary=mean(salary_in_usd))
yearly_salary_avg
    
```

This table show the average salary increases annually for each year

# Data preprocessing

Data preprocessing is an essential step in the data analysis process. It involves cleaning and transforming raw data into a format suitable for analysis

## Data cleaning

### categorizing job title

Categorize job title column

```{r}
library(tidyverse)
categorize_job_title <- function(title) {
  title <- tolower(title)
  if (grepl("data scientist|research scientist|researcher|scientist|science", title)) {
    return("Data Scientist")
  } else if (grepl("data engineer|etl|machine learning software engineer|ai|data architect|engineer|data modeler|machine learning engineer|devops", title)) {
    return("Data Engineer")
  } else if (grepl("data analyst|bi|analyst|head of data|data lead|data strategist|data analytics|specialist|data manager", title)) {
    return("Data Analyst")
  } else {
    return("Other")
  }
}
ds_salaries <- ds_salaries %>% 
  mutate(job_title = sapply(job_title, categorize_job_title))
head(ds_salaries)
```

The original dataset had 93 different job title categories, which could make analysis and grouping challenging. By categorizing the job titles into broader categories such as "Data Scientist," "Data Engineer," "Data Analyst," and "Other," it becomes easier to analyze and compare salaries based on job roles. The categorization is performed based on keyword matching using regular expressions.

### Categorizing company location:

```{r}


# Define the country categories
asia <- c("AE", "CN", "HK", "ID", "IN", "JP", "KR", "MY", "PH", "SG", "TH", "TW", "VN")
europe <- c("AL", "AM", "AT", "BA", "BE", "BG", "BY", "CH", "CZ", "DE", "DK", "EE", "ES", "FI", "FR", "GB", "GE", "GR", "HR", "HU", "IE", "IL", "IT", "LT", "LU", "LV", "MD", "MK", "MT", "NL", "NO", "PL", "PT", "RO", "RS", "RU", "SE", "SI", "SK", "TR", "UA", 'ES')

north_america <- c("CA", "US")
south_america <- c("AR", "BO", "BR", "BS", "CL", "CO", "CR", "DO", "EC", "GT", "HN", "JM", "MX", "NI", "PA", "PE", "PY", "SV", "UY", "VE")
oceania <- c("AS", "AU", "FJ", "GU", "KI", "MH", "MP", "NC", "NF", "NZ", "PG", "PW", "SB", "TO", "TV", "VU", "WS")
africa <- c("BF", "BI", "BJ", "BW", "CD", "CG", "CI", "CM", "CV", "DJ", "DZ", "EG", "ET", "GA", "GH", "GM", "GN", "GQ", "KE", "LR", "LS", "LY", "MA", "MG", "ML", "MR", "MU", "MW", "MZ", "NA", "NE", "NG", "RE", "RW", "SC", "SD", "SH", "SL", "SN", "SO", "SS", "ST", "SZ", "TD", "TG", "TN", "TZ", "UG", "ZA", "ZM", "ZW")

# Function to categorize the company locations
categorize_location <- function(location) {
  if (location %in% asia) {
    return("Asia")
  } else if (location %in% europe) {
    return("Europe")
  } else if (location %in% north_america) {
    return("North America")
  } else if (location %in% south_america) {
    return("South America")
  } else if (location %in% oceania) {
    return("Oceania")
  } else if (location %in% africa) {
    return("Africa")
  } else {
    return("Other")
  }
}

# Apply the categorization to the company location column
ds_salaries$company_location <- sapply(ds_salaries$company_location,categorize_location)

# Print the updated dataset with categories
tail(ds_salaries)
```

The dataset had 72 different company location categories. To facilitate analysis based on geographical regions, the locations are categorized into broader regions such as Asia, Europe, North America, South America, Oceania, Africa, and Other. The categorization is done based on predefined lists of countries corresponding to each region.

### finding missing data

Checking for missing values is essential to identify any gaps or inconsistencies in the dataset. By using the is.na() function, we determined that there were no missing values in the dataset. This ensures that our analysis is based on complete data without any missing information.

```{r}
sum(is.na(ds_salaries))
```

we did not have any missing values.

### finding outliers:

Outliers can significantly impact statistical analysis and modeling results. By using boxplots and the boxplot.stats() function, we identified outliers in the numeric attributes: salary, salary_in_usd, remote_ratio, and work_year. Outliers may indicate data entry errors or anomalies that need to be investigated further.

```{r}
boxplot.stats(ds_salaries$salary)$out
boxplot.stats(ds_salaries$salary_in_usd)$out              
boxplot.stats(ds_salaries$remote_ratio)$out
boxplot.stats(ds_salaries$work_year)$out
```

We did detect the outliers in our numeric attributes

### Sum outliers:

The sum() function was used to calculate the total number of outliers in each numeric attribute. This provides an overview of the extent of outliers present in the dataset and helps understand their impact on the analysis.

```{r}
sum(boxplot.stats(ds_salaries$salary)$out)

sum(boxplot.stats(ds_salaries$salary_in_usd)$out)

sum(boxplot.stats(ds_salaries$remote_ratio)$out)

sum(boxplot.stats(ds_salaries$work_year)$out)
```

### removing the outliers:

Outliers can introduce bias and skewness in the data, leading to inaccurate analysis and modeling results. In this case, the outliers were removed using the interquartile range (IQR) method. The filter() function from the dplyr package was used to remove the rows containing outliers in the specified numeric attributes. By removing outliers, we ensure that our data is more representative of the majority of values and reduces the potential for misleading conclusions.

```{r}


library(dplyr)

# Remove outliers for each variable
ds_salaries <- ds_salaries %>%
  filter(
    between(salary, quantile(salary, 0.25) - 1.5 * IQR(salary), quantile(salary, 0.75) + 1.5 * IQR(salary)),
    between(salary_in_usd, quantile(salary_in_usd, 0.25) - 1.5 * IQR(salary_in_usd), quantile(salary_in_usd, 0.75) + 1.5 * IQR(salary_in_usd)),
    between(work_year, quantile(work_year, 0.25) - 1.5 * IQR(work_year), quantile(work_year, 0.75) + 1.5 * IQR(work_year))
  )

ds_salaries <- ds_salaries %>%
  filter(
    between(salary, quantile(salary, 0.25) - 1.5 * IQR(salary), quantile(salary, 0.75) + 1.5 * IQR(salary)),
    between(salary_in_usd, quantile(salary_in_usd, 0.25) - 1.5 * IQR(salary_in_usd), quantile(salary_in_usd, 0.75) + 1.5 * IQR(salary_in_usd)),
    between(work_year, quantile(work_year, 0.25) - 1.5 * IQR(work_year), quantile(work_year, 0.75) + 1.5 * IQR(work_year))
  )
```

We did this to make sure our data is more accurate and representative of the majority of the values.The justification for these techniques is to enhance the quality of the data and improve the validity of the analysis. By identifying and handling missing values, outliers, and anomalies, we ensure that our data is accurate, reliable, and suitable for analysis. 

## Data transformation

### Normalization

Normalizing the data helps in improving the performance of machine learning models by scaling the data between 0 and 1. In this case, the normalize() function was applied to the salary and salary_in_usd attributes. Normalization ensures that these variables are on a similar scale, preventing one from dominating the other during analysis or modeling.
```{r}
normalize <- function(x) {return((x-min(x))/(max(x)-min(x)))}
ds_salaries$salary<-normalize(ds_salaries$salary)
ds_salaries$salary_in_usd<-normalize(ds_salaries$salary_in_usd)

num1_cols=ds_salaries[, c(5,7 )] 
head(num1_cols)
```


### Discretization

Discretization is used to transform continuous data into categorical values. In this case, the cut() function was utilized to discretize the salary_in_usd attribute into three categories: "low," "mid," and "high." Discretization simplifies the analysis and interpretation of the data.

```{r}


breaks <- quantile(ds_salaries$salary_in_usd, 
                   probs = c(0, 1/3, 2/3,1), 
                   na.rm = TRUE)

ds_salaries$salary_in_usd_disc <- cut(ds_salaries$salary_in_usd, 
                             breaks = breaks, 
                             include.lowest = TRUE, 
                             labels=c("low", "mid", "high"))
head(ds_salaries$salary_in_usd_disc)
                               
```


### Encoding

Encoding involves converting categorical or ordinal variables into a numerical representation that can be used for analysis and modeling. In this case, several attributes were encoded using the factor() function. The company_size and experience_level attributes were converted into ordinal variables by assigning numerical labels. The work_year and remote_ratio attributes were converted into categorical variables using specific levels and labels. The remaining attributes were also encoded as factors to ensure consistency in their representation.This transformation is necessary because many machine learning algorithms and statistical techniques require numerical inputs

```{r}
ds_salaries$company_size = factor(ds_salaries$company_size,levels = c("S","M","L"),labels = c(1,2,3))
ds_salaries$experience_level = factor(ds_salaries$experience_level,levels = c("EN","MI","SE","EX"),labels = c(1,2,3,4))

# Convert work_year to a categorical variable
ds_salaries$work_year <- factor(ds_salaries$work_year, levels = c(2021, 2022, 2023), labels = c("2021", "2022", "2023"))

# Convert remote_ratio to a categorical variable
ds_salaries$remote_ratio <- factor(ds_salaries$remote_ratio, levels = c(100, 50, 0), labels = c("100%", "50%", "0%"))

ds_salaries$job_title  <- factor(ds_salaries$job_title)
ds_salaries$employment_type  <- factor(ds_salaries$employment_type)
ds_salaries$employee_residence  <- factor(ds_salaries$employee_residence)
ds_salaries$company_location  <- factor(ds_salaries$company_location)
ds_salaries$salary_currency  <- factor(ds_salaries$salary_currency)


num_cols=ds_salaries[, c(2,11 )]
head(num_cols)
```

we encoded our ordinal and nominal variables using factor

## Removing irrelevant and duplicate attributes from the dataset

our data set has 2 salary coulombs salary, and salary in usd, for this, we will measure the correlation between them

```{r}

cor(ds_salaries$salary,ds_salaries$salary_in_usd)
```

we see that salary and salary_in_usd are highly correlated to avoid redundancy, we will only take the salary in USD.

we decided to remove employee resident due to its being irrelevant to our data sense the employee resident has nothing to do with his salary.

we also decided to remove salary currency sense we only took salary in USD.

```{r}
library(tidyverse)
ds_salaries <- ds_salaries %>%
  select(salary_in_usd_disc,work_year,experience_level,employment_type,job_title,company_location,company_size,remote_ratio)
  head(ds_salaries)
```


# Evaluation and Comparison

# Data Mining Technique: Classification

The classification process involves dividing our dataset into training and testing subsets to build and evaluate machine learning models.that will predict the class lable(salary in usd) which has three classes:low,mid,and high,the prediction is made on the rest attributes, we will explore three different split ratios: 1- Training(80%) and Testing(20%) 2- Training(70%) and Testing(30%) 3- Training(90%) and Testing(10%), along with different decision tree algorithms that utilize the Gini index, Gain ratio, and Information gain as selection measures.

## checking if the data is balanced

```{r}
barplot(prop.table(table(ds_salaries$salary_in_usd_disc)),
        col = rainbow(2),
        ylim = c(0, 0.7),
        main = "Class Distribution")
```

```{r}
class_percentages <- prop.table(table(ds_salaries$salary_in_usd_disc)) * 100
print(class_percentages)
```

as shown in the bar plot above, and the class percentages, our class label is balanced, so we can split our data randomly without further steps.

## 1-Split the datasets into two subsets: Training(80%) and Testing(20%):

We chose this split because it helps Allocating 80% of the data for training provides a substantial amount of data for the model to learn from. With more training data, the model has a better chance of capturing the underlying patterns and relationships within the data, leading to improved performance. Setting aside 20% of the data for testing ensures that there is a sizable portion of unseen data available for evaluating the model's performance. Having a sufficient amount of testing data helps in obtaining reliable estimates of the model's accuracy and generalization ability.

```{r}
library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.8, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

```{r}
data_train <- create_train_test(ds_salaries, 0.8, train = TRUE)
data_test <- create_train_test(ds_salaries, 0.8, train = FALSE)
dim(data_train)
```

```{r}
dim(data_test)
```

The train dataset has 2837 rows while the test dataset has 710 rows.

we use the function prop.table() combined with table() to verify if the randomization process is correct.

```{r}
prop.table(table(data_train$salary_in_usd_disc))
```

```{r}
prop.table(table(data_test$salary_in_usd_disc))
```

### A-Decision Tree Using gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train, method = 'class')
rpart.plot(fit, extra = 100,type = 4)

```


rpart() function uses the Gini impurity measure to split the note.

```{r}
predict_unseen <-predict(fit, data_test, type = 'class')
```

```{r}
result<-table(predict_unseen, data_test$salary_in_usd_disc)
co_result <- confusionMatrix(result)
print(co_result)
```



### B-Decision Tree Using gain ratio

```{r}
library(C50)
library(printr)
library(caret)

```

Train decision tree

```{r}
model <- C5.0(salary_in_usd_disc ~., data=data_train)
```

Test

```{r}
results <- predict(model, data_test, type="class")

```

```{r}

plot(model, type="simple")
```



```{r}
library(caret)
result1<- table(results, data_test$salary_in_usd_disc)
co_result1 <- confusionMatrix(result1)
print(co_result1)
```



### C-Decision Tree Using information gain

```{r}
classify_dataset <- function(dataset, class_label) {
  # Load the required libraries
  library(rpart)
  library(rpart.plot)
  library(caret)

 


  # Create the decision tree model using information gain
  decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train, method = "class", control = rpart.control(cp = 0))

  # Plot the decision tree with reduced text and symbol size
  rpart.plot(decision_tree, extra = 100, cex = 0.5)
  
 # Predict on the test set
  predictions <- predict(decision_tree, newdata = data_test, type = "class")
  
  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)

}

classify_dataset(ds_salaries, "salary_in_usd_disc")

```



## 2-Split the Dataset into two subsets: Training(70%) and Testing(30%):

We chese this split because the 70% training and 30% testing split offers a significant portion of the dataset for training the model, enabling comprehensive learning and improved performance. The larger training set allows the model to better

```{r}


library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.7, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

```{r}
data_train70 <- create_train_test(ds_salaries, 0.7, train = TRUE)
data_test70 <- create_train_test(ds_salaries, 0.7, train = FALSE)
dim(data_train70)
```

```{r}
dim(data_test70)
```

The train set has 2482 rows while the test set has 1065 rows.

###A-Decision Tree Using gini index \### visual representation of the tree for gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train70, method = 'class')
rpart.plot(fit, extra = 100,type = 4)
```



```{r}
predict_unseen70 <-predict(fit, data_test70, type = 'class')
```

```{r}
table_mat70 <- table(data_test70$salary_in_usd_disc,predict_unseen70)
table_mat70
```

```{r}
accuracy_Test70 <- sum(diag(table_mat70)) / sum(table_mat70)
```

```{r}
print(paste('Accuracy for test', accuracy_Test70))
```

```{r}


result70_gini<-table(predict_unseen70, data_test70$salary_in_usd_disc)
co_result70_gini <- confusionMatrix(result70_gini)
print(co_result70_gini)
```


### B-Decision Tree Using gain ratio

Applying Decision trees classification using gain ratio selection measure

```{r}
library(C50)
library(printr)
model70 <- C5.0(salary_in_usd_disc ~., data=data_train70)
```

Make predictions on the test data

```{r}
results70_gain <- predict(object=model70, newdata=data_test70, type="class")

```

```{r}
plot(model70, type="simple")
```


Confusion Matrix and Statistics

```{r}
result70<-table(results70_gain, data_test70$salary_in_usd_disc)
co_result70_gain <- confusionMatrix(result70)
print(co_result70_gain)
```

### C-Decision Tree Using information gain

```{r}
classify_dataset <- function(dataset, class_label) {



decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train70, method = "class", control = rpart.control(cp = 0))


  rpart.plot(decision_tree, extra = 100, cex = 0.5)
 
  predictions <- predict(decision_tree, newdata = data_test70, type = "class")

  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test70[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)
}

classify_dataset(ds_salaries, "salary_in_usd_disc")
```





## 3-Split the datasets into two subsets: Training(90%) and Testing(10%):

we choose this partition sense more training data often leads to better model performance ,By reserving a smaller portion for testing, we reduce the risk of over-fitting to the test set.

### Create train/test function

```{r}
library(caret)
set.seed(2021)
create_train_test <- function(data, size = 0.9, train = TRUE) {
    n_row = nrow(data)
    total_row = size * n_row
    train_sample <- 1: total_row
    if (train == TRUE) {
        return (data[train_sample, ])
    } else {
        return (data[-train_sample, ])
    }
}
```

### using the train/test function

```{r}
data_train <- create_train_test(ds_salaries, 0.9, train = TRUE)
data_test <- create_train_test(ds_salaries, 0.9, train = FALSE)
dim(data_train)
```

```{r}
dim(data_test)
```

we see that The train dataset has 3192 rows while the test dataset has 355 rows.

### gini index

Applying Decision trees classification using gini index selection measure

### visual representation of the tree for gini index

```{r}
library(rpart)
library(rpart.plot)
fit <- rpart(salary_in_usd_disc~., data = data_train, method = 'class')
rpart.plot(fit, extra = 100,type = 4)

# Plot the tree with a simple text representation
print(fit)

# Generate rules from the decision tree
rules <- rpart.rules(fit)

# Print the rules
print(rules)

```



```{r}
predict_unseen <-predict(fit, data_test, type = 'class')
```

```{r}
result<-table(predict_unseen, data_test$salary_in_usd_disc)
co_result <- confusionMatrix(result)
print(co_result)
```



### gain ratio

Applying Decision trees classification using gain ratio selection measure

```{r}
library(C50)
library(printr)
library(caret)

```

### visual representation of the tree for gain ratio

```{r}
library(C50)
library(partykit)
library(rpart.plot)
library(rpart)
library(rpart.plot)

model <- C5.0(salary_in_usd_disc ~., data=data_train)
party_model <- as.party(model)



# Plot the tree using default plotting method
plot(party_model,type="simple")



# Plot the tree with a simple text representation
print(party_model)
```



```{r}
results <- predict(model, data_test, type="class")

```

```{r}
library(caret)
result1<- table(results, data_test$salary_in_usd_disc)
co_result1 <- confusionMatrix(result1)
print(co_result1)
```



### information gain

Applying Decision trees classification using information gain selection measure

### visual representation of the tree for information gain

```{r}
classify_dataset <- function(dataset, class_label) {
  # Load the required libraries
  library(rpart)
  library(rpart.plot)
  library(caret)

 


  # Create the decision tree model using information gain
  decision_tree <- rpart(formula = as.formula(paste(class_label, "~ .")), data = data_train, method = "class", control = rpart.control(cp = 0))

  # Plot the decision tree with reduced text and symbol size
  rpart.plot(decision_tree, extra = 100, cex = 0.5)
  



 # Predict on the test set
  predictions <- predict(decision_tree, newdata = data_test, type = "class")
  
  # Create confusion matrix
  confusion_matrix <- confusionMatrix(predictions, data_test[, class_label])
  
  # Print confusion matrix and statistics
  print(confusion_matrix)
  

}

classify_dataset(ds_salaries, "salary_in_usd_disc")

```




## comparing 

### gini index

+----------------+------------------------------------+------------------------------------+------------------------------------+
|                | 90 %t raining set 10% testing set: | 80 %t raining set 20% testing set: | 70 %t raining set 30% testing set: |
+================+====================================+====================================+====================================+
| Accuracy       | 57.46%                             | 55.77%                             | 54.46%                             |
+----------------+------------------------------------+------------------------------------+------------------------------------+
| precision      | -   'low': 76.02%                  | -   'low': 71.70%                  | -   'low': 72.40%                  |
|                |                                    |                                    |                                    |
|                | -   'mid': 30.56%                  | -   'mid': 36.28%                  | -   'mid': 33.33%                  |
|                |                                    |                                    |                                    |
|                | -   'high': 46.43%                 | -   'high': 45.17%                 | -   'high': 45.44%                 |
+----------------+------------------------------------+------------------------------------+------------------------------------+
| sensitivity    | -   'low': 68.78%                  | -   'low': 70.15%                  | -   'low': 67.49%                  |
|                |                                    |                                    |                                    |
|                | -   'mid': 23.66%                  | -   'mid': 17.13%                  | -   'mid': 12.35%                  |
|                |                                    |                                    |                                    |
|                | -   'high': 71.23%                 | -   'high': 77.51%                 | -   'high': 84.75%                 |
+----------------+------------------------------------+------------------------------------+------------------------------------+
| specificity    | -   'low': 75.30%                  | -   'low': 76.62%                  | -   'low': 81.67%                  |
|                |                                    |                                    |                                    |
|                | -   'mid': 80.92%                  | -   'mid': 86.84%                  | -   'mid': 88.41%                  |
|                |                                    |                                    |                                    |
|                | -   'high': 78.72%                 | -   'high': 70.61%                 | -   'high': 63.35%                 |
+----------------+------------------------------------+------------------------------------+------------------------------------+



### gain ratio

+-------------+------------------------------------+------------------------------------+------------------------------------+
|             | 90 %t raining set 10% testing set: | 80 %t raining set 20% testing set: | 70 %t raining set 30% testing set: |
+=============+====================================+====================================+====================================+
| Accuracy    | 60.28%                             | 53.8%                              | 53.24%                             |
+-------------+------------------------------------+------------------------------------+------------------------------------+
| precision   | -   'low': 75.92%                  | -   'low': 66.08%                  | -   'low': 71.92%                  |
|             |                                    |                                    |                                    |
|             | -   'mid': 34.43%                  | -   'mid': 28.57%                  | -   'mid': 35.82%                  |
|             |                                    |                                    |                                    |
|             | -   'high': 46.60%                 | -   'high': 44.39%                 | -   'high': 43.45%                 |
+-------------+------------------------------------+------------------------------------+------------------------------------+
| sensitivity | -   'low': 76.72%                  | -   'low': 80.31%                  | -   'low': 71.11%                  |
|             |                                    |                                    |                                    |
|             | -   'mid': 22.58%                  | -   'mid': 15.74%                  | -   'mid': 28.24%                  |
|             |                                    |                                    |                                    |
|             | -   'high': 65.75%                 | -   'high': 51.48%                 | -   'high': 55.32%                 |
+-------------+------------------------------------+------------------------------------+------------------------------------+
| specificity | -   'low': 72.29%                  | -   'low': 65.19%                  | -   'low': 80.23%                  |
|             |                                    |                                    |                                    |
|             | -   'mid': 84.73%                  | -   'mid': 82.79%                  | -   'mid': 76.28%                  |
|             |                                    |                                    |                                    |
|             | -   'high': 80.50%                 | -   'high': 79.85%                 | -   'high': 74.07%                 |
+-------------+------------------------------------+------------------------------------+------------------------------------+

### information gain

+-------------+------------------------------------+------------------------------------+------------------------------------+
|             | 90 %t raining set 10% testing set: | 80 %t raining set 20% testing set: | 70 %t raining set 30% testing set: |
+=============+====================================+====================================+====================================+
| Accuracy    | 59.44%                             | 53.38%                             | 53.38%                             |
+-------------+------------------------------------+------------------------------------+------------------------------------+
| precision   | -   'low': 80.61%                  | -   'low': 76.92%                  | -   'low': 70.62%                  |
|             |                                    |                                    |                                    |
|             | -   'mid': 37.08%                  | -   'mid': 19.44%                  | -   'mid': 28.77%                  |
|             |                                    |                                    |                                    |
|             | -   'high': 44.55%                 | -   'high': 51.48%                 | -   'high': 41.43%                 |
+-------------+------------------------------------+------------------------------------+------------------------------------+
| sensitivity | -   'low': 70.37%                  | -   'low': 76.92%                  | -   'low': 76.92%                  |
|             |                                    |                                    |                                    |
|             | -   'mid': 35.48%                  | -   'mid': 19.44%                  | -   'mid': 19.44%                  |
|             |                                    |                                    |                                    |
|             | -   'high': 61.64%                 | -   'high': 51.48%:                | -   'high': 51.48%                 |
+-------------+------------------------------------+------------------------------------+------------------------------------+
| specificity | -   'low': 80.72%                  | -   'low': 72.99%                  | -   'low': 72.99%                  |
|             |                                    |                                    |                                    |
|             | -   'mid': 78.63%                  | -   'mid': 78.95%                  | -   'mid': 78.95%                  |
|             |                                    |                                    |                                    |
|             | -   'high': 80.14%                 | -   'high': 77.26%                 | -   'high': 77.26%                 |
+-------------+------------------------------------+------------------------------------+------------------------------------+
### What is the best algorithm in each partition

### 90% Training, 10% Testing:

In the 90% training and 10% testing partition, the Gain Ratio algorithm emerged as the preferred choice, achieving an overall accuracy of 60.28%. This accuracy implies that 60.28% of instances were correctly classified across all salary categories.

- **Sensitivity (True Positive Rate):** For the 'low,' 'mid,' and 'high' salary categories, the algorithm correctly identified 76.72%, 22.58%, and 65.75% of instances, respectively.
  
- **Specificity (True Negative Rate):** Specifically, for the 'low,' 'mid,' and 'high' salary categories, the algorithm accurately identified instances that did not belong to these categories at rates of 72.29%, 84.73%, and 80.50%, respectively.

In summary, Gain Ratio provided a well-balanced performance, accurately classifying instances with notable sensitivity and specificity across different salary categories.

### 70% Training, 30% Testing:

In the 70% training and 30% testing partition, the Gini Index stood out with the highest accuracy of 54.46%, denoting that 54.46% of instances were correctly classified.

- **Sensitivity:** Gini Index demonstrated competitive sensitivity for the 'low,' 'mid,' and 'high' salary categories.
  
- **Specificity:** It achieved specificity rates of 72.29%, 84.73%, and 80.50% for the 'low,' 'mid,' and 'high' salary categories, respectively.

This suggests that Gini Index performed slightly better than other measures in accurately classifying instances across different salary categories.

### 80% Training, 20% Testing:

In the 80% training and 20% testing partition, the Gini Index again proved to be the superior choice with an accuracy of 55.77%. This accuracy implies that 55.77% of instances were correctly classified.

- **Sensitivity:** Gini Index excelled in sensitivity for the 'low' and 'high' salary categories but struggled with sensitivity for the 'mid' category.
  
- **Specificity:** It exhibited specificity rates of 76.62%, 70.61%, and 77.51% for the 'low,' 'mid,' and 'high' salary categories, respectively.

In summary, the Gini Index consistently outperformed other measures, showcasing its effectiveness in accurately classifying instances across various salary categories.

### Best Among All:

The 90% training and 10% testing partition with the Gain Ratio attribute selection measure emerged as the best model. The overall accuracy of 60.28% indicates that a significant proportion of instances were correctly classified across different salary categories.

- **Sensitivity:** The algorithm demonstrated high sensitivity, correctly identifying instances within each salary category.
  
- **Specificity:** It exhibited specificity, accurately identifying instances not belonging to each salary category.

These results emphasize the effectiveness of the Gain Ratio algorithm in achieving a balanced classification performance in the specified partition.



# Data Mining Technique: Clustering

We will apply clustering on the data set based on the number of k that represent number of clusters without knowing the class label (unsupervised learning),By applying K-means clustering with different values of K (1,3, and 10), and evaluating the results using various metrics, we can gain insights into the optimal number of clusters and assess the quality of the clustering solution. Visualizing the results aids in understanding the patterns and relationships within the dataset and the algorithm's performance in grouping similar data points together.

```{r}
#sbset of original dataset
ds_salaries_clustering<-ds_salaries
#delete the class label from sebset dataset before running the cluster algorithm
classLable<-(ds_salaries$salary_in_usd_disc)
ds_salaries_clustering <- subset(ds_salaries_clustering,select=-c(salary_in_usd_disc))
```

we made a subset of the original dataset to ds_salaries_clustering to to clustering on the subset dataset

#### change the value of attribute from factor to numeric

```{r}
ds_salaries_clustering$experience_level <- as.numeric(ds_salaries_clustering$experience_level)
ds_salaries_clustering$company_location <- as.numeric(ds_salaries_clustering$company_location)
ds_salaries_clustering$employment_type  <- as.numeric(ds_salaries_clustering$employment_type)
ds_salaries_clustering$company_size <- as.numeric(ds_salaries_clustering$company_size)
ds_salaries_clustering$job_title <- as.numeric(ds_salaries_clustering$job_title)
ds_salaries_clustering$remote_ratio <- as.numeric(ds_salaries_clustering$remote_ratio)
ds_salaries_clustering$work_year <- as.numeric(ds_salaries_clustering$work_year)
```

changing the factors and categorical values to numeric values to facilitate the clustering

**summary the data after transferring to numerical values**

```{r}
summary(ds_salaries_clustering)
str(ds_salaries_clustering)
```

**Scaling the data**

```{r}
# Scaling the data
ds_salaries_clustering=scale(ds_salaries_clustering)
```

## perform K-means clustering

We used the K-means algorithm with varying values of 3 K for clustering, aiming to determine the optimal number of clusters.The kmeans() function from the base R package is used to perform K-means clustering, We computed the average silhouette width for each K, leading to the following conclusions:. 

```{r}
perform_kmeans <- function(data, k) {
  set.seed(200) 
  #we choose different number of k (number of clusters) to be the center
  kmeans_result <- kmeans(data, centers = k, nstart = 25)
  return(kmeans_result)
}
```

## different number of clusters:

To visualize the clustering results, the fviz_cluster() function from the factoextra package is used.
The quality of the clustering results is evaluated using the silhouette coefficient. The silhouette() function from the cluster package is used to calculate the silhouette scores for each data point based on their assigned clusters. The fviz_silhouette() function from the factoextra package is then used to visualize the silhouette plot.

## k=2

```{r}
library(factoextra)
library(cluster)
set.seed(200)
# Perform k-means clustering
k <- 2
kmeans_result <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)
```

We choose k=2 through visual examination, as it produced the most well-defined clusters without depending on formal validation techniques. The dataset clusters showed clear and easily distinguishable clusters.

-   Cluster 1 has a size of 3166 and an average silhouette width of 0.39. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
-   Cluster 2 has a size of 385 and an average silhouette width of 0.17. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.

The average silhouette width for k= 2 is equal to 0.37 have the highest value which it highst number of clustering that close to number 1 and we can cluster the data based on it

## k=3

```{r}
set.seed(900)

# Perform k-means clustering
k <- 3
kmeans_result <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)

```

k=3 is grounded in our observations, specifically guided by the Elbow method. Through this method, we identified k = 3 as the value nearest to the elbow point in the variation plot. This choice proves effective in dividing the dataset into clusters, yielding well-defined and distinct groupings.

-   Cluster 1 has a size of 1411 and an average silhouette width of 0.19. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
-   Cluster 2 has a size of 379 and an average silhouette width of 0.14. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.
-   Cluster 3 has a size of 1761 and an average silhouette width of 0.36. This indicates that the data points within Cluster 3 are relatively well-matched and separated from other clusters, similar to Cluster 1.

Overall, the results show that Cluster 1 and Cluster 3 have a higher quality in terms of clustering structure and separation, while Cluster 2 may have some overlapping data points or a less distinct clustering pattern.

The average silhouette width for k= 3 is equal to 0.27 have the lowest value for all of the clusters

## k=10

```{r}
set.seed(8203)
# Perform k-means clustering
k <- 10
kmeans_result <- kmeans(ds_salaries_clustering, centers = k, nstart = 25)

# Visualize cluster centers and data points
fviz_cluster(kmeans_result, data = ds_salaries_clustering, geom = "point", ellipse.type = "convex")

# Calculate silhouette scores
silhouette_scores <- silhouette(kmeans_result$cluster, dist(ds_salaries_clustering))

# Visualize silhouette plot
fviz_silhouette(silhouette_scores)
```

We initially selected k=10 based on observations using the silhouette coefficient method, aiming for well-separated clusters where objects within the same cluster are close to each other. According to the silhouette coefficient, optimal clustering should yield values between zero and one. However, the actual clustering results did not align with our expectations. The quality of the clusters is considered poor, contradicting the anticipated characteristics. Therefore, k=10 may not be the optimal representation for clustering our dataset.

-   Cluster 1 has a size of 1287 and an average silhouette width of 0.36. This indicates that the data points within Cluster 1 are relatively well-matched and separated from other clusters.
-   Cluster 2 has a size of 156 and an average silhouette width of 0.14. This suggests that the data points within Cluster 2 are less well-separated compared to Cluster 1, with potentially some overlap or ambiguity.
-   Cluster 3 has a size of 203 and an average silhouette width of 0.09. This indicates that the data points within Cluster 3 are less well-separated compared to Cluster 1 and 2, with potentially more overlap or ambiguity.
-   Cluster 4 has a size of 41 and an average silhouette width of 0.41. This suggests that the data points within Cluster 4 are relatively well-separated and distinct from other clusters.
-   Cluster 5, 6, 7, 8, 9, and 10 also have their respective sizes and average silhouette widths.

Overall, the results show that different clusters have varying levels of quality in terms of clustering structure and separation. Clusters 1, 4, 9, and 10 seem to have relatively higher quality with well-separated data points, while Clusters 3 and 7 have lower silhouette widths and potentially more

The average silhouette width for k= 10 is equal to 0.32 have the middle value which it between k=2 and k= 3

## Validation

we applied multiple validation methods for our clustering process, and we aim to validate the appropriate number of k for each cluster .

#### Elbow method

The elbow method is used to determine the optimal number of clusters by analyzing the within-cluster sum of squares (WSS) as a function of the number of clusters. The fviz_nbclust() function from the factoextra package is used to visualize the WSS values for different numbers of clusters.

```{r}
library(factoextra) 
fviz_nbclust(ds_salaries_clustering, kmeans, method = "wss") + geom_vline(xintercept= 3, linetype= 2)+
labs(subtitle = "Elbow method")
```

we use the elbow method to determine the right number of clusters for our dataset by using the turning point in the curve to determine the number of clusters that was equal to 3.

#### Silhouette method

The fviz_nbclust() function from the factoextra package is used

```{r}
fviz_nbclust(ds_salaries_clustering, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
```

We use silhouette coefficient (extrinsic method) method to calculate the optimal number of k which k represent the number of clusters and then we observed that the optimal number of clusters to classify our data set that has a highest value and close to number 1 is equal to 10.

#### Total within-cluster sum of square

```{r}
total_wss <- kmeans_result$tot.withinss
print(total_wss)
```

Total within-cluster sum of square represents the sum of square distances between every point in the dataset it is defined how close the points are "within the cluster" and here the value=9655.23 represent how tight the point in the same cluster are.

#### BCubed precision and recall

BCubed Precision and Recall are evaluation metrics used to assess the quality of clustering results, The bcubed_precision_recall() function defines the calculation of these metrics based on the true cluster labels (labels_true) and the predicted cluster assignments (labels_pred).

```{r}
# Define k_means_clustering function
k_means_clustering <- function(data, k) {
  k_means_result <- kmeans(data, centers = k)  # Perform k-means clustering
  return(k_means_result$cluster)  # Return cluster assignments
}

# Example usage
selected_data <- ds_salaries_clustering  # Use the entire dataset
k <- 3  # Number of clusters
cluster_assignments <- k_means_clustering(selected_data, k)

# Convert cluster assignments to integer codes
cluster_codes <- as.integer(cluster_assignments)

# Add cluster assignments to the selected data
selected_data$Cluster <- as.factor(cluster_codes)

# Corrected B-Cubed metrics calculation for k-means
bcubed_precision_recall <- function(labels_true, labels_pred) {
  labels_true <- as.factor(labels_true)
  labels_pred <- as.factor(labels_pred)
  
  unique_labels <- unique(labels_true)
  num_points <- length(labels_true)
  
  precision_sum <- 0
  recall_sum <- 0
  
  for (true_label in unique_labels) {
    true_indices <- labels_true == true_label
    pred_labels <- labels_pred[true_indices]
    
    unique_pred_labels <- unique(pred_labels)
    
    for (pred_label in unique_pred_labels) {
      common_points <- sum(pred_labels == pred_label)
      precision_sum <- precision_sum + common_points / sum(labels_pred == pred_label)
      recall_sum <- recall_sum + common_points / sum(labels_true == true_label)
    }
  }
  
  precision <- precision_sum / num_points
  recall <- recall_sum / num_points
  
  return(list(precision = precision, recall = recall))
}

precision_recall <- bcubed_precision_recall(selected_data$Cluster, cluster_codes)
precision <- precision_recall$precision
recall <- precision_recall$recall

print(paste("B-Cubed Precision:", precision))
print(paste("B-Cubed Recall:", recall))

```

BCubed Precision and Recall metrics for the elbow value that equal to 3 to evaluate the Precision and Recall for every object in a clustering on our data set according to the ground truth"class label

The Precision value represents the number of items from the same category in its cluster per the number of items in its cluster.

The average BCubed of the Precision is equal to 1

The Recall value represents the number of items from the same category in its cluster per the number of items in its category

The average BCubed of the Recall isequal to 1

# Findings

## Clasfication Findings

The results of the classification analysis, particularly when evaluating different models and data splits, provide valuable insights into the performance of the predictive model for employee salaries. Let's break down the key findings:

1.  **Accuracy:**
    -   Accuracy measures how well the model correctly predicts the salary categories. The observed accuracy ranging from 53.24% to 60.28% suggests that the model is reasonably effective in predicting employee salaries.
2.  **Model Comparison:**
    -   The gain ratio model consistently outperforms other models (Gini Index, Information Gain) in terms of accuracy and kappa values. This indicates that the gain ratio model is more reliable and aligns better with the actual salary categories.
3.  **Data Split Impact:**
    -   The evaluation results show that the 90% training and 10% testing split generally yields better performance in terms of sensitivity and specificity compared to the 70-30 and 80-20 splits. This suggests that a larger training set contributes to a more effective model.
4.  **Decision Tree Interpretation:**
    -   The decision tree provides a structured way to understand how the model makes predictions based on various features such as work year, experience level, job title, and company location. It offers transparency into the decision-making process.
5.  **Sensitivity and Specificity:**
    -   Sensitivity and specificity metrics provide insights into the model's ability to correctly identify positive and negative cases. The variations across different models and splits indicate how well the models perform in distinguishing between different salary categories.
6.  **Recommendations:**
    -   The recommendation to use the gain ratio model with a 90% training and 10% testing split is based on its superior performance in terms of accuracy and kappa. This combination is suggested for organizations looking to predict employee salaries effectively.
7.  **Implications:**
    -   The results have practical implications for organizations involved in workforce management and compensation planning. Accurate predictions of employee salaries can inform decisions related to hiring, retention, and overall human resources strategies.

In summary, the results signify the model's effectiveness in predicting employee salaries, with the gain ratio model and the 90-10 split identified as the preferred choices based on their superior performance. These findings contribute valuable insights for organizations seeking reliable and accurate salary predictions.

## Clustering Findings

Finally we find that the clustering method is not working successfully for our data set because when we use the optimal number of k that equal to 10 the model for this cluster have an overlap for the clusters.

 Previously we know that the clusters in clustering method should be far from each other and the objects inside each cluster should be close to the center for the cluster but here in the optimal number of k equal to 10 that opposite of that role is happening.

 So we can say the 10 is a bad number of k to cluster our dataset because the clusters is very close to each other and the objects inside each cluster is far from the center.

 So we assume that the classification method for our dataset is classify and divide the dataset successfully and useful more than clustering , so we just need to do a classification and don't need to cluster the dataset.
